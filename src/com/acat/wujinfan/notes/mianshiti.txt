①，一面的面试题总结

1，HashMap实现原理，ConcurrentHashMap实现原理。

<1>HashMap，底层hash表，在jdk 1.7以前是数组与链表，jdk1.8以后是链表长度达到8时会演变成红黑树（维持数据的插入和查找的效率平衡）。
<2>ConcurrentHashMap，是hashMap的演变，在jdk 1.7以前是segement分段加锁，为了减少锁竞争。
每次的数据查找经历两次hash，第一次hash先找到segement，第二次hash是查找segement段内的链表位置，在写入数据时对segement加锁.
每个版本查找数据的特殊地方：1.6以前是找到节点数据才加锁（外层调用不加锁），1.7以后都是使用Unsafe.getObjectVolatile。
ConcurrentHashMap 1.8以后是数组和链表，不再使用segement，直接对每个链表进行加锁，更进一步降低锁竞争，put操作是使用了synchronize对当前链表加锁，get是使用Unsafe.getObjectVolatile获取最新的共享内存值（利用cas不加锁），为了保证获取的数据是最新的（可见性）

Segement的modCount变更条件：调用put或者remove操作，并且导致元素新增或者被删除，才能引起变化，如果仅仅覆盖或者删除不成功，不会导致变化。
Size()方法：其实就是在每个segement modcount相同情况下（否则马上再次发起重试），再校验count的总数（查两次），如果不同，重试两次，如果还是不同，就对每个segement加锁。

补充：LinkedList、ArrayList，LinkedHashMap
<1>LinkedList：底层是基于双向链表（非环状）实现，为什么使用双向链表？为了提高数据的查找效率（包括指定index位置插入），因此内部会根据index和size做比较，决定从头部向后或者尾部向前开始遍历，如当我们调用get(int location)时，首先会比较“location”和“双向链表长度的1/2”；若前者大，则从链表头开始往后查找，直到location位置；否则，从链表末尾开始先前查找，直到location位置。

特点：LinkedList查找效率低，增删效率更高，可以利用零碎的内存空间。

<2>ArrayList：是基于动态数组实现的，如果空间不够的时候，增加新元素时要动态扩容数组（期间还需要拷贝数据到新数组），删除元素时也需要对后面的数据进行向前移动整合（因为后面还需要使用index搜索数据）。
特点：ArrayList的查找效率高，而增删操作的效率低（只能使用连续的内存空间），使用建议：空间可以申请大一些，尽量不要删除数据。

ArrayList中的modCount，继承于AbstractList，这个成员变量记录着集合的修改次数，也就每次add或者remove它的值都会加1，在使用迭代器遍历集合的时候同时修改集合元素。因为ArrayList被设计成非同步的，因此会抛出异常，实现原理：获取迭代器的时候，会记录一个expectedModCount（不会被改变），在每次迭代过程中会校验expectedModCount和modCount是否相等，否则会抛出异常ConcurrentModificationException

<3>LinkedHashMap：继承了HashMap，因此底层还是哈希表结构（数组+链表），但是另外多维护了一个双向环状链表（只有一个头结点），提供了插入有序和访问有序（lru）两种模式，默认为插入有序（打印的结果就是之前的插入顺序），LinkedHashMap重写了的内部addEntry（put调用）方法，重写了Entry，包含before, after，为了将来能构建一个双向的链表，当向map里面添加数据时，在createEntry时，把新创建的Entry加入到双向链表中，之所以使用双向环状链表就是为了实现访问有序，每次访问，都把节点调整到头结点前面（实际上变成了尾节点）。
简单总结：当put元素时，不但要把它加入到HashMap中去，还要加入到双向链表中，所以可以看出LinkedHashMap就是HashMap+双向环状链表

参考：https://www.jianshu.com/p/8f4f58b4b8ab，https://blog.csdn.net/qq_28051453/article/details/71169801

补充：为什么Hashtable ConcurrentHashmap不支持key或者value为null
ConcurrentHashmap和Hashtable都是支持并发的，这样会有一个问题，当你通过get(k)获取对应的value时，如果获取到的是null时，你无法判断（除非全程在插入、查询时加锁判断，此时性能就下降了），它是put（k,v）的时候value为null，还是这个key从来没有做过映射。HashMap是非并发的，可以通过contains(key)来做这个判断。而支持并发的Map在调用m.contains（key）和m.get(key),m可能已经不同了。
参考：https://blog.csdn.net/gagewang1/article/details/54971965

2，红黑树，为什么允许局部不平衡
完全平衡二叉树的左右两个子树的高度差的绝对值不超过1，因此每次的节点变更都需要保证树的严格平衡。
红黑树只需要保证从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点，因此红黑树是一颗接近完全平衡的二叉树，减少了旋转次数，提高数据的写入效率。

红黑树特点：
（1）每个节点或者是黑色，或者是红色。
（2）根节点是黑色。
（3）每个叶子节点（NIL）是黑色。 [注意：这里叶子节点，是指为空(NIL或NULL)的叶子节点！]
（4）如果一个节点是红色的，则它的子节点必须是黑色的。
（5）从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点。

补充：插入节点默认是红色（第五点限制），红黑树具体的旋转：https://www.cnblogs.com/skywang12345/p/3624343.html

平衡二叉搜索树：又被称为AVL树（有别于AVL算法），且具有以下性质：它是一 棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。平衡二叉树的常用实现方法有红黑树、AVL、替罪羊树、Treap、伸展树等。

普通的二叉查找树：容易失去”平衡“，极端情况下，二叉查找树会退化成线性的链表，导致插入和查找的复杂度下降到 O(n) ，所以，这也是平衡二叉树设计的初衷。那么平衡二叉树如何保持”平衡“呢？根据定义，有两个重点，一是左右两子树的高度差的绝对值不能超过1，二是左右两子树也是一颗平衡二叉树

树的补充：https://blog.csdn.net/qq_25940921/article/details/82183093

3，tcp三次握手，四次挥手，为什么不是2次握手？

<1>三次握手(Three-way Handshake)，是指建立一个TCP连接时，需要客户端和服务器总共发送3个包
 TCP是一个双向通信协议，客户端向服务端建立连接需要得到服务端ack响应，意味着客户端向服务端通信正常，此时客户端再给服务端回复一个ack，意味着服务端向客户端通信正常，这样才能正确建立起来双工通信通道，因此两次握手不能保证服务端向客户端通信是否正常。

<2>TCP的连接的拆除需要发送四个包，因此称为四次挥手(four-way handshake)。客户端或服务器均可主动发起挥手动作，在socket编程中，任何一方执行close()操作即可产生挥手操作。
客户端或服务器可以单独关闭向另外一端的通信通道，即为半关闭状态，因此才进行四次挥手。
为什么需要半关闭？比如只需要向一方传输资源，传输完毕以EOF标记即可。

4，tcp和udp的区别，为什么是可靠和不可靠的？
<1>TCP协议是有连接的，有连接的意思是开始传输实际数据之前TCP的客户端和服务器端必须通过三次握手建立连接，会话结束之后也要结束连接。而UDP是无连接的
<2>TCP协议保证数据按序发送，按序到达，提供超时重传来保证可靠性，但是UDP不保证按序到达，甚至不保证到达，只是努力交付，即便是按序发送的序列，也不保证按序送到。
<3>TCP有流量控制和拥塞控制，UDP没有，网络拥堵不会影响发送端的发送速率
<4>TCP是一对一的连接，而UDP则可以支持一对一，多对多，一对多的通信。
<5>TCP面向的是字节流的服务，UDP面向的是报文的服务

TCP的可靠性含义： 接收方收到的数据是完整， 有序， 无差错的。
UDP不可靠性含义： 接收方接收到的数据可能存在部分丢失， 顺序也不一定能保证。

备注：GET和POST还有一个重大区别，简单的说：GET产生一个TCP数据包;POST产生两个TCP数据包。

长的说：
对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200(返回数据);
而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok(返回数据)。

post请求的过程：
（1）浏览器请求tcp连接（第一次握手）
（2）服务器答应进行tcp连接（第二次握手）
（3）浏览器确认，并发送post请求头（第三次握手，这个报文比较小，所以http会在此时进行第一次数据发送）
（4）服务器返回100 Continue响应
（5）浏览器发送数据
（6）服务器返回200 OK响应
get请求的过程：
（1）浏览器请求tcp连接（第一次握手）
（2）服务器答应进行tcp连接（第二次握手）
（3）浏览器确认，并发送get请求头和数据（第三次握手，这个报文比较小，所以http会在此时进行第一次数据发送）
（4）服务器返回200 OK响应
也就是说，目测get的总耗是post的2/3左右，这个口说无凭，网上已经有网友进行过测试。

参考：https://blog.csdn.net/zzk220106/article/details/78595108/

5，TCP滑动窗口和socket缓冲区之间的关系
TCP的滑动窗口大小实际上就是socket的接收缓冲区大小的字节数，“窗口”对应的是一段可以被发送者发送的字节序列，其连续的范围称之为“窗口”；每次成功发送数据之后，发送窗口就会在发送缓冲区中按顺序移动，将新的数据包含到窗口中准备发送。

6，tcp拥塞控制
网络中的链路容量和交换结点中的缓存和处理机都有着工作的极限，当网络的需求超过它们的工作极限时，就出现了拥塞。拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。常用的方法就是：
1. 慢开始、拥塞控制
2. 快重传、快恢复

补充说明：慢开始是指发送方先设置cwnd=1，一次发送一个报文段，随后每经过一个传输轮次，拥塞串口cwnd就加倍，其实增长并不慢，以指数形式增长。还要设定一个慢开始门限，当cwnd>门限值，改用拥塞避免算法。拥塞避免算法使cwnd按线性规律缓慢增长。当网络发生延时，门限值减半，拥塞窗口执行慢开始算法。（先指数级别增加，再线性增加，延迟再衰减）

快重传的机制是：
接收方建立这样的机制，如果一个包丢失，则对后续的包继续发送针对该包的重传请求，一旦发送方接收到三个一样的确认，就知道该包之后出现了错误，立刻重传该包；

此时发送方开始执行“快恢复”算法：
慢开始门限减半；
cwnd设为慢开始门限减半后的数值；
执行拥塞避免算法（高起点，线性增长）
参考：https://www.cnblogs.com/woaiyy/p/3554182.html

7，mysql事务是什么？四大特性，四大隔离级别
事务：事务处理可以用来维护数据库的完整性，保证成批的 SQL 语句要么全部执行，要么全部不执行，是最小的不可再分的工作单元。
四大特性，原子性，隔离性，持久性，一致性。
四大隔离级别：
事务隔离级别	              脏读    不可重复读	幻读
读未提交（read-uncommitted）	是	是	是
读已提交（read-committed）		否	是	是
可重复读（repeatable-read）	否	否	是
串行化（serializable）	        否	否	否
serializable级别是最高的
mysql默认的事务隔离级别为repeatable-read

   ① Serializable (串行化)：可避免脏读、不可重复读、幻读的发生。
　　② Repeatable read (可重复读)：可避免脏读、不可重复读的发生。
　　③ Read committed (读已提交)：可避免脏读的发生。
　　④ Read uncommitted (读未提交)：最低级别，任何情况都无法保证。

　　以上四种隔离级别最高的是Serializable级别，最低的是Read uncommitted级别，当然级别越高，执行效率就越低。像Serializable这样的级别，就是以锁表的方式(类似于Java多线程中的锁)使得其他的线程只能在锁外等待，所以平时选用何种隔离级别应该根据实际情况。在MySQL数据库中默认的隔离级别为Repeatable read (可重复读)。

　　在MySQL数据库中，支持上面四种隔离级别，默认的为Repeatable read (可重复读)；而在Oracle数据库中，只支持Serializable (串行化)级别和Read committed (读已提交)这两种级别，其中默认的为Read committed级别。

8，spring ioc和aop，各自有什么优点？

ioc，依赖注入，在以前的软件工程编码过程中，类的属性需要硬编码生成对象数据，耦合性较高，如果使用ioc，是在容器启动过程中，在bean对象实例化过程中需要检查其依赖数据，并且进行数据注入（setter，构造器注入），完成一个对象的实例化并实现了解耦合，并且能够对这些对象进行复用。

aop，主要分为两大类：一是采用动态代理技术，利用截取消息的方式，对该消息进行装饰，以取代原有对象行为的执行；二是采用静态织入的方式，引入特定的语法创建“方面”，从而使得编译器可以在编译期间织入有关“方面”的代码。它利用一种称为"横切"的技术，并将那些影响了多个类的公共行为封装到一个可重用模块，简单理解是抽象出与业务逻辑无关的公共行为逻辑。

9，java有哪几种线程池
         //线程池大小固定为1
         Executors.newSingleThreadExecutor();

        //固定大小线程池由自己设定，即自己控制资源的固定分配
        Executors.newFixedThreadPool(10);

        //动态调整线程池的大小，最小为0，最大为int最大值，，newCachedThreadPool会大幅度提高大量短暂异步任务的性能，
        //如果执行业务逻辑比较慢，会导致持续创建线程，导致cpu资源消耗殆尽
        //为什么使用SynchronousQueue？最多只能持有一个任务数据，当任务数据插入队列失败，会驱动创建新线程
        Executors.newCachedThreadPool();

        //基于延迟队列实现的延时任务线程池，周期性的执行所提交的任务
        ScheduledExecutorService scheduledExecutorService = Executors.newScheduledThreadPool(10);
        scheduledExecutorService.scheduleAtFixedRate(new Runnable() {
            @Override
            public void run() {
                System.out.println(Thread.currentThread().getName() + " run");
            }
        }, 1000,2000, TimeUnit.MILLISECONDS);

10，什么情况下使用Thread和Runnable创建线程，Runnable和Callable区别
 两个都可以实现多线程编程，但是基于java是单继承和多实现，所以实现Runable更灵活，并且Runable可以简单的实现变量的线程间共享。
 Runnable和Callable区别：
 实现Callable接口的任务线程能返回执行结果；而实现Runnable接口的任务线程不能返回结果；
 Callable接口的call()方法允许抛出异常；而Runnable接口的run()方法的异常只能在内部消化，不能继续上抛；

11，线程方法中的异常如果处理？父线程可以捕获到吗？
在run方法体里面必须主动捕获check exception，如果是unchecked exception（RunntimeException）可以给线程注册一个UncaughtExceptionHandler，发生异常时执行回调。
通过Callable创建的线程，可以在futureTask.get()获取结果时捕获异常。

12，synchronized和lock区别，什么情况下使用synchronized和Reentrantlock ？
1.首先synchronized是java内置关键字，在jvm层面，Lock是个java类；
2.synchronized无法判断是否获取锁的状态，Lock可以判断是否获取到锁；
3.synchronized会自动释放锁(a 线程执行完同步代码会释放锁 ；b 线程执行过程中发生异常会释放锁)，Lock需在finally中手工释放锁（unlock()方法释放锁），否则容易造成线程死锁；
4.用synchronized关键字的两个线程1和线程2，如果当前线程1获得锁，线程2线程等待。如果线程1阻塞，线程2则会一直等待下去，而Lock锁就不一定会等待下去，如果尝试获取不到锁，线程可以不用一直等待就结束了；
5.synchronized的锁可重入、不可中断、非公平，而Lock锁可重入、可中断、可判断、可公平（两者皆可）
6.Lock锁适合大量同步的代码的同步问题，synchronized锁适合代码少量的同步问题

备注：synchronized适合低并发的场景，锁竞争发生的概率很小，此时锁处于偏向锁或者轻量级锁状态，因此性能更加好，比如jdk1.8concurrentHashMap为什么使用synchronized的原因就是，每个hash槽上的锁竞争很少，用synchronized比lock更好

13，jvm的对象分配在哪个区，Class对象分配在哪个区？
线程共享的变量分配在堆（实例）和方法区（静态变量等）里面，非线程共享的变量在栈区
Class对象分配在堆里面，Class的元数据是在方法区里面

14，一次http请求的全过程，包括域名解析、主机定位等。
<1>域名解析，分为如下几个步骤（找不到逐步递归）
A，查找浏览器的dns缓存（域名与ip的映射表）
B，查找自身操作系统自身的DNS缓存，
C，查找自身的host文件
D，请求打到运营商的dns服务器，访问运营商的dns缓存。
E，访问全球顶级域名解析器，获得将要寻址域名的权限域名服务器地址（用来保存该区中的所有主机域名到IP地址的映射，如baidu.com的域名ip管理机器）
F，运营商dns访问权限域名服务器获取目标域名的ip。

<2>tcp三次握手
<3>建立TCP连接后发起http请求（get，post由发起者决定）
　  HTTP请求报文由三部分组成：请求行，请求头和请求正文
　　请求行：用于描述客户端的请求方式，请求的资源名称以及使用的HTTP协议的版本号（例：GET/books/java.html HTTP/1.1）
　　请求头：用于描述客户端请求哪台主机，以及客户端的一些环境信息等
　　注：这里提一个请求头 Connection，Connection设置为 keep-alive用于说明 客户端这边设置的是，本次HTTP请求之后并不需要关闭TCP连接，这样可以使下次HTTP请求使用相同的TCP通道，节省TCP建立连接的时间
　　请求正文：当使用POST, PUT等方法时，通常需要客户端向服务器传递数据。这些数据就储存在请求正文中（GET方式是保存在url地址后面，不会放到这里）
<4>服务器端响应http请求，浏览器得到html代码
　　HTTP响应也由三部分组成：状态码，响应头和实体内容
　　状态码：状态码用于表示服务器对请求的处理结果
　　列举几种常见的：200（没有问题） 302（要你去找别人） 304（要你去拿缓存） 307（要你去拿缓存） 403（有这个资源，但是没有访问权限） 404（服务器没有这个资源） 500（服务器这边有问题）
　　若干响应头：响应头用于描述服务器的基本信息，以及客户端如何处理数据
　　实体内容：服务器返回给客户端的数据
　　注：html资源文件应该不是通过 HTTP响应直接返回去的，应该是通过nginx通过io操作去拿到的吧

<5>浏览器解析html代码，并请求html代码中的资源
<6>断开TCP连接（四次挥手）
<7>页面渲染给用户

总结：域名解析 --> 发起TCP的3次握手 --> 建立TCP连接-->发起http请求 --> 服务器响应http请求，浏览器得到html代码 --> 浏览器解析html代码，并请求html代码中的资源（如js、css、图片等）-->tcp四次挥手 --> 浏览器对页面进行渲染呈现给用户



②，二面的面试题总结
1，常用设计模式的介绍，单例模式，装饰模式，及使用场景

单例模式：
public class SingletonTest {
    private static volatile SingletonTest singletonTest;

    public SingletonTest getInstance() {
        if (singletonTest == null) {
            synchronized (SingletonTest.class) {
                if (singletonTest == null) {
                    singletonTest = new SingletonTest();
                }
            }
        }
        return singletonTest;
    }
}
使用场景：全局只需要初始化一个实例对象，节省内存开销（比如spring bean的单例配置）

装饰模式
public class DecoratorTest {
    public interface Greeting {
        void sayHello();
    }

    public static class GreetingImpl implements Greeting {
        @Override
        public void sayHello() {
            System.out.println("GreetingImpl run");
        }
    }

    public static abstract class GreetingDecorator implements Greeting {
        private Greeting greeting;

        public GreetingDecorator(Greeting greeting) {
            this.greeting = greeting;
        }

        @Override
        public void sayHello() {
            greeting.sayHello();
        }
    }

    public static class GreetingBefore extends GreetingDecorator {
        public GreetingBefore(Greeting greeting) {
            super(greeting);
        }

        @Override
        public void sayHello() {
            before();
            super.sayHello();
        }

        private void before() {
            System.out.println("Before");
        }
    }

    public static void main(String[] args) throws FileNotFoundException {
        Greeting greeting = new GreetingBefore(new GreetingImpl());
        greeting.sayHello();

    }
}

代理模式重在于对方法的控制，添加行为对于用户是被动的；装饰模式重在于装饰方法，增加方法的功能，添加装饰对于用户是主动的（代理模式和装饰模式看起来很相像）

2，Java会出现内存溢出吗？什么情况下会出现？
   内存溢出（Out Of Memory，OOM），就是内存不够用了，内存泄漏（Memory Leak），指的是申请的内存空间，自己没有去主动释放，gc也无法释放（如强引用），多次内存泄漏，就会导致内存溢。

3，双亲委派模型，为什么这样做？
当一个类加载和初始化的时候，类仅在有需要加载的时候被加载。假设你有一个应用需要的类叫作Abc.class，首先加载这个类的请求由Application类加载器委托给它的父类加载器Extension类加载器，然后再委托给Bootstrap类加载器。Bootstrap类加载器会先看看rt.jar中有没有这个类，因为并没有这个类，所以这个请求由回到Extension类加载器，它会查看jre/lib/ext目录下有没有这个类，如果这个类被Extension类加载器找到了，那么它将被加载，而Application类加载器不会加载这个类；而如果这个类没有被Extension类加载器找到，那么再由Application类加载器从classpath中寻找。

双亲委托可以避免重复加载，当父亲已经加载了该类的时候，就没有必要子ClassLoader再加载一次（单一性）。

4，对象什么情况下进入老年代？
<1>申请大对象，young区无法存放这么大的对象，此时需要在老年代申请空间。
<2>young区中的eden区对象经过多次Minor GC晋升到Survivor区，如果还存活，就会移动到老年代。

补充：
<1>full gc发生条件：System.gc()调用，老年代空间不足，perm（方法区，即永生代）空间不足。
<2>young区为什么要有Survivor区？只要进行一次MinorGC，存活的对象就进入了old区，导致old区很快写满，就会频繁出发full gc，进而引发99线波动很大。
<3>young区为什么要有2个Survivor区？如果使用单个Survivor，eden区和Survivor经过Minor GC之后存活的对象存放在单个Survivor，可能出现碎片化，使用两个就不会（每次gc后s0和s1之间交换数据，保证有一个无碎片，一个为空）
<4>young和old区比例一般是1:2，eden和s0，s1是8:1:1
参考：https://blog.csdn.net/towads/article/details/79784249

5，快速排序说一下（todo）

6，Spring AOP原理说下
AOP是切面编程，所谓切面编程是把与业务无关的公共逻辑抽象成一个公共方法执行。AOP的实现是通过动态代理，动态代理有两种实现方式，jdk自带的动态代理（运行时生成一个新的代理类，代理类通过反射机制获取被代理类的方法，完成被代理方法的执行），cglib在类加载时通过探针技术(javaAgent和ASM，均是字节码修改工具)修改被代理类的字节码，生成新的class，完成被代理类的方法调用。
两者区别：Jdk动态代理针对接口，cglib针对类。

7，BIO、NIO（如何实现的）、AIO
先简介一下同步、异步、阻塞、非阻塞的概念
同步：调用者（用户线程，如selector线程）调用一个服务，必须自己主动等待结果，中间可以做别的事情，但是得要轮询结果。
异步：调用者（用户线程）调用一个服务，不需要等待业务逻辑执行完，就可以去别的事情，之前业务逻辑处理完，会通知调用者。
关注点：执行结果获取结果方式（主动、被动（回调））

阻塞：调用结果没有返回之前，会持续等待结果（调用者线程被阻塞，cpu没有交出去）
非阻塞：调用结果没有返回之前，调用者线程不会被阻塞。
关注点：用户线程是否被阻塞

BIO：同步阻塞io
NIO：同步非阻塞io，需要多路复用器Selector进行调度，执行结果需要多路复用器询问。
AIO：异步非阻塞io，执行结果由os进行回调通知

使用场景：
BIO：使用连接数较少，服务器压力很低的架构。
NIO方式适用于连接数目多且连接比较短（轻操作）的架构，比如聊天服务器，并发局限于应用中，编程比较复杂，JDK1.4开始支持。
AIO方式使用于连接数目多且连接比较长（重操作）的架构，比如相册服务器，充分调用OS参与并发操作，编程比较复杂，JDK7开始支持。

AIO在性能上相对于NIO没有本质的提升。
AIO只是帮助你从内核中将数据复制到用户空间中，并调用你传入的回调方法（内核完成回调）。
NIO是需要程序自己从内核中将数据复制到用户空间中，并需要程序自己调用相应的处理逻辑。

补充：在微服务架构里面，服务响应都比较快，aio并不比nio响应快多少，因此netty实现上也就不使用aio。

8，消息中间件有哪些？它们之间的优劣势？
ActiveMQ：单机吞吐量在万级，比RocketMQ和Kafka低一个数量级，传统中小企业用的多一些，没有大规模吞吐场景验证，没有活跃社区，有较低的概率丢失数据（不是百分百可靠），支持事务。
RabbitMQ：单机吞吐量在万级，比RocketMQ和Kafka低一个数量级，基于erlang开发，不利于java开发者深入研究，其可靠性非常高，有活跃社区，不支持事务。
RocketMQ：吞吐量10万级（高吞吐，低延迟），单机支持topic可达到好几百，基于java开发（客户端只支持java），有活跃社区，支持事务。
Kafka：吞吐量10万级（高吞吐，低延迟），客户端支持多种语言，单机topic过多时，会导致性能下降，此时需要增加机器，有活跃社区，不支持事务。

参考：https://www.jianshu.com/p/eaafb1581e55，https://www.jianshu.com/p/2838890f3284

9，redis的持久化方式
 RDB：在指定的时间间隔能对数据进行快照存储。
   优点：使用单独子进程来进行持久化，主进程不会进行任何IO操作，保证了redis的高性能
   缺点：RDB是间隔一段时间进行持久化，如果持久化之间redis发生故障，会发生数据丢失，数据的准确性不高。
   AOF：AOF持久化方式记录每次对服务器写的操作,当服务器重启的时候会重新执行这些命令来恢复原始的数据,AOF命令以redis协议追加保存每次写的操作到文件末尾，Redis还能对AOF文件进行后台重写,使得AOF文件的体积不至于过大。
   优点：可以保持更高的数据完整性，因此已成为主流的持久化方案
   缺点：AOF文件比RDB文件大，且恢复速度慢。

补充：redis如何压缩AOF文件，具体过程如下：
redis调用fork ，现在有父子两个进程
<1>，子进程根据内存中的数据库快照，往临时文件中写入重建数据库状态的命令
<2>，父进程继续处理client请求，除了把写命令写入到原来的aof文件中。同时把收到的写命令缓存起来。这样就能保证如果子进程重写失败的话并不会出问题。
<3>，当子进程把快照内容写入已命令方式写到临时文件中后，子进程发信号通知父进程。然后父进程把缓存的写命令也写入到临时文件。
<4>，现在父进程可以使用临时文件替换老的aof文件，并重命名，后面收到的写命令也开始往新的aof文件中追加。
<5>，需要注意到是重写aof文件的操作，并没有读取旧的aof文件，而是将整个内存中的数据库内容用命令的方式重写了一个新的aof文件,这点和快照有点类似。

简单总结：如何缩小AOF文件大小：文件重写是指定期重写AOF文件（产生新的AOF文件），减小AOF文件的体积。需要注意的是，AOF重写是把Redis进程内的数据转化为写命令，同步到新的AOF文件（为了压缩aof的持久化文件。redis提供了bgrewriteaof命令。收到此命令redis将使用与快照类似的方式将内存中的数据 以命令的方式保存到临时文件中，最后替换原来的文件）

10，栈和队列（todo）

参考：https://www.cnblogs.com/smyhvae/p/4795984.html，https://blog.csdn.net/z_x_m_m_q/article/details/82804923

11，jvm垃圾回收算法
<1>标记-清除算法
这种垃圾回收一次回收分为两个阶段：标记、清除。首先标记所有需要回收的对象，在标记完成后回收所有被标记的对象。这种回收算法会产生大量不连续的内存碎片，当要频繁分配一个大对象时，jvm在新生代中找不到足够大的连续的内存块，会导致jvm频繁进行内存回收(目前有机制，对大对象，直接分配到老年代中)
场景：如果没有Survivor，eden区gc后会产生很多碎片。
<2>复制算法
这种算法会将内存划分为两个相等的块，每次只使用其中一块。当这块内存不够使用时，就将还存活的对象复制到另一块内存中，然后把这块内存一次清理掉。这样做的效率比较高，也避免了内存碎片。但是这样内存的可使用空间减半，是个不小的损失。
场景：在发生young gc的时候，Survivor0和Survivor1之间的数据相互复制迁移。

<3>标记-整理算法(标记压缩法)
这是标记-清除算法和复制算法的综合版，在完成标记阶段后，不是直接对可回收对象进行清理，而是让存活对象向着一端移动，然后清理掉边界以外的内存，避免产生内存碎片。

<4>分代收集算法
这是对上面三种算法的综合应用，并且采取分代处理，当前商业虚拟机都采用这种算法。首先根据对象存活周期的不同将内存分为几块即新生代、老年代，然后根据不同年代的特点，采用不同的收集算法。

补充：

1，Java GC如何判断对象是否为垃圾（https://www.cnblogs.com/hzzjj/p/6268432.html）
<1>引用计数法，引用计数法就是如果一个对象没有被任何引用指向，则可视之为垃圾。这种方法的缺点就是不能检测到环的存在。
<2>根搜索算法，主流的虚拟机都是采用GC Roots Tracing算法，比如Sun的Hotspot虚拟机便是采用该算法。 该算法的核心算法是从GC Roots对象作为起始点，利用数学中图论知识，图中可达对象便是存活对象，而不可达对象则是需要回收的垃圾内存。
那么可以作为GC Roots的对象：
 A,虚拟机栈的栈帧的局部变量表所引用的对象；
 B,本地方法栈的JNI所引用的对象；
 C,方法区的静态变量和常量所引用的对象；


垃圾回收器

Cms垃圾回收器：CMS(Concurrent Mark-Sweep)是以牺牲吞吐量为代价来获得最短回收停顿时间的垃圾回收器，老年代的回收采用CMS，使用算法：标记清除法（参考：https://blog.csdn.net/hutongling/article/details/69908443）

工作过程：
<1>初始标记：在这个阶段，需要虚拟机停顿正在执行的任务，官方的叫法STW(Stop The Word)，所以这个过程虽然暂停了整个JVM，但是很快就完成了。初始标记也就是标记一下GC roots 关联到的对象。（并不是所有活动对象）。
<2>并发标记：这个阶段紧随初始标记阶段，在初始标记的基础上继续向下追溯标记。并发标记阶段，应用程序的线程和并发标记的线程并发执行，所以用户不会感受到停顿。并发标记就需要标记出GC roots关联到的对象的引用对象有哪些。比如说 A -> B (A 引用 B，假设 A是GC Roots关联到的对象)，那么这个阶段就是标记出B对象，A对象会在初始标记中标记出来。
<3>重新标记（也会stw），之前在并发标记时，因为是GC和用户程序是并发执行的，可能导致一部分已经标记为 从GC Roots不可达 的对象，因为用户程序的（并发）运行，又可达了（对象被复活了），Remark的作用就是将这部分对象又标记为 可达对象。
<4>并发清理：清理垃圾对象，这个阶段收集器线程和应用程序线程并发执行。
初始标记和重新标记都要stop the world

重新标记（Remark） 的作用在于：
之前在并发标记时，因为是 GC 和用户程序是并发执行的，可能导致一部分已经标记为 从 GC Roots 不可达 的对象，因为用户程序的（并发）运行，又可达 了，Remark 的作用就是将这部分对象又标记为 可达对象。
至于 “浮动垃圾”，因为 CMS 在 并发标记 时是并发的，GC 线程和用户线程并发执行，这个过程当然可能会因为线程的交替执行而导致新产生的垃圾（即浮动垃圾）没有被标记到；而 重新标记 的作用只是修改之前 并发标记 所获得的不可达对象，所以是没有办法处理 “浮动垃圾” 的。



Cms的缺点：
<1>CMS不会整理和压缩堆空间，导致产生问题：经过CMS收集的堆会产生空间碎片（不压缩空间是为了响应更快），典型的空间换时间（实际可以配置经过多少次old gc之后整理old区，减少内存碎片）
<2>需要更多的CPU资源，不直接使用多线程，直接利用多核cpu。
<3>CMS的另一个缺点是它需要更大的堆空间，为了保证在CMS回收完堆之前还有空间分配给正在运行的应用程序，CMS不会在老年代满的时候才开始收集，在空间到了68%就开始回收。
<4>cms会产生浮动垃圾，由于在应用运行的同时进行垃圾回收，所以有些垃圾可能在垃圾回收进行完成时产生，这样就造成了“Floating Garbage”，这些垃圾需要在下次垃圾回收周期时才能回收掉。所以，并发收集器一般需要20%的预留空间用于这些浮动垃圾。


G1垃圾回收器，回收算法是：标记整理，减少内存碎片化

G1是在JDK 7u4版本之后发布的垃圾收集器，并在jdk9中成为默认垃圾收集器，G1也是利用多CPU来缩短stop the world时间（弱化了分代的概念，g1能同时作用于新生代和老年代），并且是高效的并发垃圾收集器。但是G1不再像上文所述的垃圾收集器，需要分代配合不同的垃圾收集器，因为G1中的垃圾收集区域是“分区”（Region）的。G1的分代收集和以上垃圾收集器不同的就是除了有年轻代的ygc，全堆扫描的fullgc外，还有包含所有年轻代以及部分老年代Region的MixedGC。G1的优势还有可以通过调整参数，指定垃圾收集的最大允许pause time。下面会详细阐述下G1分区以及分代的概念，以及G1 GC的几种收集过程的分类。

G1的优点：
0. 弱化young区和old区概念，把堆区分为若干小的区域region，这些region 可分为young,surival,old,humergus,默认分为2048个区，每块1～32M
1，同时对多个regoin进行并发标记，每次GC不需要清理全部的堆区域，只需要清理垃圾最多的分区，这样可以减少stw的时间，提升了jvm的响应性能。
2，不同区域region不需要连续。活跃数据在不同region复制和移动。
3，单个大对象可以存放多个humergus之间，可以有效利用空间。
4，G1根据回收时间的可预计性（时间可配置），一次回收一定数量的region，减少stw时间。

参考：https://www.cnblogs.com/niejunlei/p/5989814.html

备注：G1的收集都是STW的，但年轻代和老年代的收集界限比较模糊，采用了混合(mixed)收集的方式。即每次收集既可能只收集年轻代分区(年轻代收集)，也可能在收集年轻代的同时，包含部分老年代分区(混合收集)，这样即使堆内存很大时，也可以限制收集范围，从而降低停顿。G1采用内存分区(Region)的思路，将内存划分为一个个相等大小的内存分区，回收时则以分区为单位进行回收，存活的对象复制到另一个空闲分区中。由于都是以相等大小的分区为单位进行操作，因此G1天然就是一种压缩方案(局部压缩)。


G1的工作流程：
1：初始标记，STW。基于yong GC，标记survivor中可能引用老年代对象的对象，作为Root Region，并扫描
2：并发标记：贯穿整个堆内存，标记活跃对象，并立即清除，同时收集活跃对象统计信息。
3：重新标记：使用snapshot-at-the-beginning（SATB），移除，回收标记的空region。STW
4：清理/复制，G1选择最不活跃的region，以便最快收集。这些区域可以和yong GC同时收集，STW
清理：统计活跃对象，活跃区域（STW）=》清理RSet（STW）=》重置空的region=》归还到free list（并发）。
复制：移动活跃对象到未应用的区域（STW)

发生full gc条件：当收集垃圾，从一个区域复制数据到另一个区域时，找不到可用区域。

12，MySql索引

<1>InnoDB（b+树，聚簇索引）：支持事务处理，支持外键，支持崩溃修复能力和并发控制。如果需要对事务的完整性要求比较高（比如银行），要求实现并发控制（比如售票），那选择InnoDB有很大的优势。如果需要频繁的更新、删除操作的数据库，也可以选择InnoDB，因为支持事务的提交（commit）和回滚（rollback）（用于事务处理应用程序，具有众多特性，包括ACID事务支持。(提供行级锁)）

<2>MyISAM（b+树，非聚簇索引）：插入数据快，空间和内存使用比较低。如果表主要是用于插入新记录和读出记录，那么选择MyISAM能实现处理高效率。如果应用的完整性、并发性要求比较低，也可以使用（MyISAM类型不支持事务处理等高级处理，因此也不支持数据的回滚修复）。

<3>MEMORY（hash结构）：所有的数据都在内存中，数据的处理速度快，但是安全性不高。如果需要很快的读写速度，对数据的安全性要求较低，可以选择MEMOEY。它对表的大小有要求，不能建立太大的表。所以，这类数据库只使用在相对较小的数据库表。

为什么使用b+树？
在范围查询方面，B+树的优势更加明显，B树的范围查找需要不断进行遍历查找每个数据（查一次，进行一次io）。首先二分查找到范围下限，在不断通过遍历，知道查找到范围的上限即可。整个过程比较耗时，而B+树的范围查找则简单了许多。首先通过二分查找，找到范围下限，然后同过叶子结点的链表顺序遍历，直至找到上限即可，整个过程简单许多，效率也比较高。（b+树的数据都分布在子节点上）。B+树的空间相对比较大，典型的空间换时间。

13，tomcat类加载器
在tomcat7版本下，Tomcat自己定义了两个核心类加载器，JasperLoader负责加载jsp文件经过编译生成的jsp类，该类加载器打破了双亲委托机制(为什么打破双亲委托机制？实现jsp文件的热部署)。webappclassLoader只负责加载web项目下的lib类（分析源码并没有打破双亲委托机制）

14，内存泄漏，什么情况下会发生，如何排查？
指的是申请的内存空间，自己没有去主动释放，gc也无法释放（如强引用），多次内存泄漏，就会导致内存溢出，在生成环境中对某些大对象的不合理使用（没有用的对象没被释放），导致gc回收不了。
如何排查：用jmap生成堆内存信息文件（常说的内存dump）， MAT（Memory Analyzer Tool），Eclipse提供的一款用于Heap Dump文件的工具，MAT分析堆信息文件，包括整个堆内存的大小、类（Class）的数量、对象（Object）的数量、类加载器（Class Loader)的数量、以及所占的空间大小。
补充：jstack查看线程堆栈信息，排查死锁用的比较多。

16，spi，service provice interface，其实是一套协议，使用者不用关注其实现，各个功能实现者针对标准进行实现就可以了，比如jdbc的数据库驱动，各个厂商有自己的具体实现

③，三面
1，介绍你实践的性能优化例子，以及你优化的思路
结合自己在做的具体业务，同步变异步（无强依赖的服务调用改成并发调用），异地缓存多活，异地双主mysql，hystrix熔断，限流机制，99线统计，热点数据缓存化等等。

2，微服务和soa的区别，优劣势？

SOA：微服务是细粒度的SOA(面向服务架构)，一个SOA组件可以拆分成多个微服务，SOA的服务架构依赖ESB企业服务总线（专注应用程序服务的可重用性的最大化）。
微服务：微服务架构是一个大的系统按照功能拆分成很多独立的子服务，每个子服务独立实现自己的业务逻辑，各个微服务之间的关联通过暴露api来实现。这些独立的微服务不需要部署在同一个虚拟机，同一个系统和同一个应用服务器中（微服务架构专注于解耦）。

SOA架构的优点
<1>系统松耦合，提高传统企业的功能模块的可重用性。
<2>决企业系统间的通信问题，把原先散乱、无规划的系统间的网状结构，梳理成 规整、可治理的系统间星形结构。

SOA架构的缺点
<1>严重依赖比较重的ESB企业服务总线，企业总线出了问题，就导致整个架构的不可能。
<2>服务粗化，比如读写负载不同的功能耦合在一个服务里面。

微服务架构模式优点：
<1>由于每个服务都是独立并且微小的，由单独的团队负责，采用敏捷开发模式，迭代效率很高。
<2>每一个微服务都是独立部署的，可根据当前服务的负载程度选择不同配置的机器。

微服务架构的缺点：
<1>微服务应用作为分布式系统带来了复杂性。各个微服务进行分布式独立部署，由不同的技术团队维护，因此经常出现跨团队沟通，效率容易不可控。
<2>微服务架构一般使用各个独立数据库，分布式事务的实现更具挑战性。
<3>测试微服务变得复杂，通常一个服务会依赖很多服务，测试环境下其他服务的不可靠，容易影响测试进度。

备注：企业服务总线(ESB)就是一条企业架构的总线，所有的企业服务都挂接到该总线上对外公布，企业服务总线负责管理服务目录，解析服务请求者的请求方法、消息格式，并对服务提供者进行寻址，转发服务请求

3，sql慢查询的优化方案，索引和表的优化方案
慢查询优化方案：
<0>explain检查sql语句是否索引覆盖
<1>能使用主键查询的尽量使用主键查询
<2>连接查询代（join on）替子查询（in）和联合查询（from t1，t2），避免在内存从形成巨大的笛卡尔积，多表连接时，尽量小表驱动大表，即小表join大表
<3>批量扫表时，每次查询应该使用上次查询返回的主键id作为下一轮的查询条件，提高查询效率。
<4>组合索引使用应该满足最左原则。
<5>数据量比较的时候，尽量使用limit进行物理分页查询
<6>查询时，返回结果能不要*就不用*，尽量写全字段名

索引优化：
<1>只要列中含有NULL值，就最好不要在此例设置索引，复合索引如果有NULL值，此列在使用时也不会使用索引
<2>尽量使用短索引，索引字段不易过长
<3>尽量不要使用not in和<>操作
<4>对于like语句，以%或者‘-’开头的不会使用索引，以%结尾会使用索引
<5>尽量不要在列上进行运算（函数操作和表达式操作）
<6>字段范围很窄（比如只有1，2，3种可能），就没必要建立索引，对查询效率没有太大的提升。

表的优化：
<1>表的字段尽可能用NOT NULL
<2>字段长度固定的表查询会更快
<3>数据量超过2000w级别的，可以考虑分表


4，Mysql和MongoDB的区别，海量数据量如何存储？
Mysql是关系型数据库，MongoDB是非关系型文档数据库。

备注：MongoDB将数据存储为一个文档，数据结构由键值(key=>value)对组成。MongoDB 文档类似于 JSON 对象。字段值可以包含其他文档，数组及文档数组。

<1>Mysql：无论数据还是索引都存放在硬盘中。到要使用的时候才交换到内存中，能够处理远超过内存总量的数据，单表单库不适合存储海量数据。

<2>MongoDB，虚拟内存+持久化，在适量级的内存的 MongoDB 的性能是非常迅速的，它将热数据存储在物理内存中，使得热数据的读写变得十分快，MongoDB 的所有数据实际上是存放在硬盘的，所有要操作的数据通过mmap的方式映射到内存某个区域内。然后MongoDB 就在这块区域里面进行数据修改，避免了零碎的硬盘操作。
MongoDB的索引放在内存中，能够提升随机读写的性能。如果索引不能完全放在内存，一旦出现随机读写比较高的时候，就会频繁地进行磁盘交换，MongoDB 的性能就会急剧下降（MongoDB不支持事务）

海量数据处理：MongoDB 以BSON结构（二进制）进行存储，对海量数据存储有着很明显的优势，支持服务端脚本和Map/Reduce，可以实现海量数据计算，即实现云计算功能。

参考：https://blog.csdn.net/CatStarXcode/article/details/79513425

5，缓存框架，例如redis和memcache之间的区别，优劣势
<1>存储策略：memcached超过内存比例会抹掉前面的数据，而redis拒绝写入内存。
<2>支持数据类型：memcached只支持string，redis支持更多。如：hash，list，set，sorted。
<3>redis支持两种持久化策略(rdb，aof)，memcached
<4>灾难恢复–memcache挂掉后，数据不可恢复; redis数据丢失后可以通过rdb、aof方式恢复。
<5>memcache是单进程多线程，redis是单线程的。
<6>Memcached单个key-value大小有限，一个value最大只支持1MB，而Redis最大支持512MB
<7>分布式–设定memcache集群，利用magent做一主多从;redis可以做一主多从。都可以一主一从。
<8>memcache是两阶段hash（第一次是一致性hash先找集群中的实例，第二次是找kv数据），redis是通过crc16算法计算出slot中的位置，再通过hash查找出数据。

6，请描述一下一致性hash算法
具体算法过程为：先构造一个长度为232次方的整数环（这个环被称为一致性Hash环），根据节点名称的Hash值（其分布为[0, 232次方-1]）将缓存服务器节点放置在这个Hash环上，然后根据需要缓存的数据的Key值计算得到其Hash值（其分布也为[0, 232-1]），然后在Hash环上顺时针查找距离这个Key值的Hash值最近的服务器节点，完成Key到服务器的映射查找。
举例：三个Node点分别位于Hash环上的三个位置，然后Key值根据其HashCode，在Hash环上有一个固定位置，位置固定下之后，Key就会顺时针去寻找离它最近的一个Node，把数据存储在这个Node的Cache（如memcache）服务器中。

一致性hash算法解决的问题：主要是考虑到分布式系统每个节点都有可能失效，或者新的节点很可能动态的增加进来的情况，我们只需要移动最少的数据，就可以保证数据的均匀分配
一致性hash算法，减少了数据映射关系的变动，不会像hash(i)%N那样带来全局的变动
普通的余数hash，分流时机器宕机会产生失败请求，容易引起请求丢失。即使mod值（hash取模值）变化，如果是redis集群，要重新移动key进行分配，数据迁移
普通的余数hash（hash(比如用户id)%服务器机器数）算法伸缩性很差，当新增或者下线服务器机器时候，用户id与服务器的映射关系会大量失效。
一致性hash环的数据倾斜问题：一致性Hash算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜（被缓存的对象大部分集中缓存在某一台服务器上）问题

参考：https://www.cnblogs.com/lpfuture/p/5796398.html，https://www.cnblogs.com/color-my-life/p/5799903.html

7，分布式session的共享方案有哪些，有什么优劣势
背景：Session是服务器用来保存用户操作的一系列会话信息，由Web容器进行管理。单机情况下，不存在Session共享的情况，分布式情况下，如果不进行Session共享会出现请求落到不同机器要重复登录的情况，一般来说解决Session共享有以下几种方案。

<1>、session复制
session复制是早期的企业级的使用比较多的一种服务器集群session管理机制。应用服务器开启web容器的session复制功能，在集群中的几台服务器之间同步session对象，使得每台服务器上都保存所有的session信息（不同功能应用的机器保存了其它应用的session），这样任何一台宕机都不会导致session的数据丢失，服务器使用session时，直接从本地获取。

缺点：应用集群变的庞大以后，就会出现瓶颈，每台都需要备份session，占用的空间变的非常大，出现内存不够用的情况。

<2>，利用cookie记录session
session记录在客户端，每次请求服务器的时候，将session放在请求中发送给服务器，服务器处理完请求后再将修改后的session响应给客户端。这里的客户端就是cookie。

缺点：受cookie大小的限制，能记录的信息有限；每次请求响应都需要传递cookie，影响性能，如果用户关闭cookie，访问就不正常。

<3>session持久化(mysql)
缺点：不适合高并发的场景，mysql读取性能受限。

<4>session绑定
利用hash算法，比如nginx的ip_hash,使得同一个ip的请求分发到同一台服务器上。
缺点：这种方式不符合对系统的高可用要求，因为一旦某台服务器宕机，那么该机器上的session也就不复存在了，用户请求切换到其他机器后么有session，无法完成业务处理。

参考：https://www.jianshu.com/p/221f8a42be33

<5>session服务器
session服务器（基于redis、memcache存储）可以解决上面的所有的问题，利用独立部署的session服务器（集群）统一管理session，服务器每次读写session时，都访问session服务器（需要我们实现session集群服务的高可用）


8，高并发情况，系统的优化方案有哪些？以及优先级排序

④，其它题目补充
1，自旋锁和偏向锁
背景：并发编程中synchronized是重量级锁，但随着JVM1.6对synchronized进行优化后，有些情况下它并不那么重，实际上性能不亚于lock。
Synchronized的锁升级过程：偏向锁--》轻量级锁--》重量级锁
整个过程是单向的，不支持降级。

简单理解：单线程（thread1）状态是使用偏向锁，thread1线程在执行过程中，别的线程（thread2）过来，发现锁处于锁处于偏向锁状态，thread2会把锁改成轻量级锁，此时thread2进入自旋状态（类似while的死循环），并且不释放cpu直至等待到锁，实际上自旋状态有超时限制的（避免长时间消耗cpu）。thread2运行过程中，thread3过来获取锁，发现锁处于轻量级锁状态，会升级成重量级锁（这种场景一般都是处于高并发状态了）。

偏向锁
大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。当一个线程访问同步块并获取锁(通过cas机制)时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入（锁重入）和退出同步块时不需要进行CAS操作来加锁和解锁，只需简单地测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁。如果测试成功，表示线程已经获得了锁。如果测试失败，则需要再测试一下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁）：如果没有设置，则使用CAS竞争锁；如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。
注意：当锁有竞争关系的时候，需要解除偏向锁，进入轻量级锁。

轻量级锁
<1>加锁
线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。
<2>解锁
轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。

自旋锁
自旋锁原理非常简单，如果持有锁的线程能在很短时间内释放锁资源，那么那些等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态，它们只需要等一等（自旋），等持有锁的线程释放锁后即可立即获取锁，这样就避免用户线程和内核的切换的消耗。但是线程自旋是需要消耗cup的，说白了就是让cup在做无用功，如果一直获取不到锁，那线程也不能一直占用cup自旋做无用功，所以需要设定一个自旋等待的最大时间（最大自旋次数）。如果持有锁的线程执行的时间超过自旋等待的最大时间扔没有释放锁，就会导致其它争用锁的线程在最大等待时间内还是获取不到锁，这时争用线程会停止自旋进入阻塞状态。


参考：https://www.jianshu.com/p/1ea87c152413，https://blog.csdn.net/zqz_zqz/article/details/70233767
补充：关于cas，cmpxchg的底层讲解，参考：https://www.cnblogs.com/luconsole/p/4944304.html

2，volatile关键字
<1>内存可见性，线程修改完变量数据后，会立马写入到共享内存中，其它线程若读取该变量，会强制从共享内存中获取，但是不能保证线程安全（已经加载进入栈空间的变量，只有再次读取，才会从共享内存取数据），volatile修饰的变量，在写入共享内存的时候，是使用cpu的lock指令，这个过程是lock内核总线，保证数据的安全性。
<2>防止指令重排，编译阶段，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序（普通的代码程序，编译器在编译期对没有前后依赖关系的代码做一些重排优化）。

3，Synchronized，volatile，reentrantlock的底层实现存在的关联
<1>Synchronized在获取同步监视器的时候，是使用cas机制修改对象头，cas机制在cpu实现上使用lock（cmpxchg）指令锁住总线。
<2>volatile在数据写入共享内存时也使用lock指令锁住总线，保证共享内存数据可见性。
<3>reentrantlock实现使用了AQS，AQS基于cas机制实现，底层也使用了lock指令。


3，什么是数组和链表？什么情况下使用二者

其它面试题：
1，https://mp.weixin.qq.com/s/Y2lxsucvkWsXbmOKPPfFjQ?
2，https://mp.weixin.qq.com/s/bc4cc6OUEc3QA6-lf91wpQ
3，https://mp.weixin.qq.com/s/TarTEBF3NTGbMx6XzN8pSA?
4，https://mp.weixin.qq.com/s/aPSOH1VoL9JRLuVamFgO4Q

其它知识点总结
1，什么是缓存击穿？
缓存是加速系统响应的一种途径，通常情况下只有系统的部分数据。当请求了缓存中没有的数据时，这时候就会回源到DB里面。此时如果黑客故意对上面数据发起大量请求，则DB有可能会挂掉，这就是缓存击穿。当然缓存挂掉的话，正常的用户请求也有可能造成缓存击穿的效果。（实际应用中经常遇到第三方爬虫，也容易导致缓存击穿）
解决缓存击穿的方案：布隆过滤器
bloom算法类似一个hash set，用来判断某个元素（key）是否在某个集合中。
和一般的hash set不同的是，这个算法无需存储key的值，对于每个key，只需要k个比特位，每个存储一个标志，用来判断key是否在集合中。
算法：
1. 首先需要k个hash函数，每个函数可以把key散列成为1个整数
2. 初始化时，需要一个长度为n比特的数组，每个比特位初始化为0
3. 某个key加入集合时，用k个hash函数计算出k个散列值，并把数组中对应的比特位置为1
4. 判断某个key是否在集合时，用k个hash函数计算出k个散列值，并查询数组中对应的比特位，如果所有的比特位都是1，认为在集合中。
优点：不需要存储key，节省空间

2，netty的Reactor模式为什么使用多线程模型?(参考：https://blog.csdn.net/xiaolang85/article/details/37873059，https://www.cnblogs.com/TomSnail/p/6158249.html)

<1>单线程模型存在的问题：

由于Reactor模式使用的是同步非阻塞IO，所有的IO操作都不会导致阻塞，理论上一个线程可以独立处理所有IO相关的操作。从架构层面看，一个NIO线程确实可以完成其承担的职责。例如，通过Acceptor类接收客户端的TCP连接请求消息，链路建立成功之后，通过Dispatch将对应的ByteBuffer派发到指定的Handler上进行消息解码。用户线程可以通过消息编码通过NIO线程将消息发送给客户端。
对于一些小容量应用场景，可以使用单线程模型。但是对于高负载、大并发的应用场景却不合适，主要原因如下：
1）一个NIO线程同时处理成百上千的链路，性能上无法支撑，即便NIO线程的CPU负荷达到100%，也无法满足海量消息的编码、解码、读取和发送；
2）当NIO线程负载过重之后，处理速度将变慢，这会导致大量客户端连接超时，超时之后往往会进行重发，这更加重了NIO线程的负载，最终会导致大量消息积压和处理超时，成为系统的性能瓶颈；
3）可靠性问题：一旦NIO线程意外跑飞，或者进入死循环，会导致整个系统通信模块不可用，不能接收和处理外部消息，造成节点故障。

备注：比如一次netty访问一个网络io，返回的数据是二进制流，此时如果让selector线程（实际是netty中的boss和worker线程）负责反序列化，就会阻塞selector，无法接受更多的连接，这种模型明显不合理的。

<2>Reactor多线程模型
Reactor多线程模型的特点：
1）有专门一个NIO线程-Acceptor线程用于监听服务端，接收客户端的TCP连接请求；
2）网络IO操作-读、写等由一个NIO线程池负责，线程池可以采用标准的JDK线程池实现，它包含一个任务队列和N个可用的线程，由这些NIO线程负责消息的读取、解码、编码和发送；
3）1个NIO线程可以同时处理N条链路，但是1个链路只对应1个NIO线程（1个NIO线程可以处理所有的链路）
在绝大多数场景下，Reactor多线程模型都可以满足性能需求；但是，在极个别特殊场景中，一个NIO线程负责监听和处理所有的客户端连接可能会存在性能问题。例如并发百万客户端连接，或者服务端需要对客户端握手进行安全认证，但是认证本身非常损耗性能。在这类场景下，单独一个Acceptor线程可能会存在性能不足问题，为了解决性能问题，产生了第三种Reactor线程模型-主从Reactor多线程模型。

<3>主从多线程模型
主从Reactor线程模型的特点是：服务端用于接收客户端连接的不再是个1个单独的NIO线程，而是一个独立的NIO线程池。Acceptor接收到客户端TCP连接请求处理完成后（可能包含接入认证等），将新创建的SocketChannel注册到IO线程池（sub reactor线程池）的某个IO线程上，由它负责SocketChannel的读写和编解码工作。Acceptor线程池仅仅只用于客户端的登陆、握手和安全认证，一旦链路建立成功，就将链路注册到后端subReactor线程池的IO线程上，由IO线程负责后续的IO操作。

利用主从NIO线程模型，可以解决1个服务端监听线程无法有效处理所有客户端连接的性能不足问题。
它的工作流程总结如下：
从主线程池中随机选择一个Reactor线程作为Acceptor线程，用于绑定监听端口，接收客户端连接；
Acceptor线程接收客户端连接请求之后创建新的SocketChannel，将其注册到主线程池的其它Reactor线程上，由其负责接入认证、IP黑白名单过滤、握手等操作；
步骤2完成之后，业务层的链路正式建立，将SocketChannel从主线程池的Reactor线程的多路复用器上摘除，重新注册到Sub线程池的线程上，用于处理I/O的读写操作。

<4>服务端线程模型
一种比较流行的做法是服务端监听线程和IO线程分离，类似于Reactor的多线程模型(Netty同时支持Reactor的单线程、多线程和主从多线程模型，在不同的应用中通过启动参数的配置来启动不同的线程模型)
第一步，从用户线程发起创建服务端操作
通常情况下，服务端的创建是在用户进程启动的时候进行，因此一般由Main函数或者启动类负责创建，服务端的创建由业务线程负责完成。在创建服务端的时候实例化了2个EventLoopGroup，1个EventLoopGroup实际就是一个EventLoop线程组，负责管理EventLoop的申请和释放。
EventLoopGroup管理的线程数可以通过构造函数设置，如果没有设置，默认取-Dio.netty.eventLoopThreads，如果该系统参数也没有指定，则为可用的CPU内核数 × 2。
bossGroup线程组实际就是Acceptor线程池，负责处理客户端的TCP连接请求，如果系统只有一个服务端端口需要监听，则建议bossGroup线程组线程数设置为1。
workerGroup是真正负责I/O读写操作的线程组，通过ServerBootstrap的group方法进行设置，用于后续的Channel绑定。

第二步，Acceptor线程绑定监听端口，启动NIO服务端，相关代码如下：
从bossGroup中选择一个Acceptor线程监听服务端
其中，group()返回的就是bossGroup，它的next方法用于从线程组中获取可用线程，代码如下：
选择Acceptor线程
服务端Channel创建完成之后，将其注册到多路复用器Selector上，用于接收客户端的TCP连接，核心代码如下：
图2-5 注册ServerSocketChannel 到Selector
第三步，如果监听到客户端连接，则创建客户端SocketChannel连接，重新注册到workerGroup的IO线程上。首先看Acceptor如何处理客户端的接入：
图2-6 处理读或者连接事件
调用unsafe的read（）方法，对于NioServerSocketChannel，它调用了NioMessageUnsafe的read()方法，代码如下：
图2-7 NioServerSocketChannel的read()方法
最终它会调用NioServerSocketChannel的doReadMessages方法，代码如下：
图2-8 创建客户端连接SocketChannel
其中childEventLoopGroup就是之前的workerGroup, 从中选择一个I/O线程负责网络消息的读写。
第四步，选择IO线程之后，将SocketChannel注册到多路复用器上，监听READ操作。
图2-9 监听网络读事件
第五步，处理网络的I/O读写事件，核心代码如下：
图2-10 处理读写事件


备注：Dubbo默认的底层网络通讯使用的是Netty，服务提供方NettyServer使用两级线程池，其中 EventLoopGroup(boss) 主要用来接受客户端的链接请求，并把接受的请求分发给 EventLoopGroup(worker) 来处理，boss和worker线程组我们称之为IO线程。

3，dubbo常见面试题（https://blog.csdn.net/Y0Q2T57s/article/details/83005376）
<1>dubbo为什么使用线程池
实际上是可以选择是否使用线程池，如果不使用线程池，对于一些长耗时的网络io（响应的数据比较大），selector线程（实际就是netty中的worker线程）会阻塞在处理结果（比如网络io响应的结果进行序列化），导致selector无法接受更多的请求，这些长耗时的逻辑应该下沉到业务线程池里面，与netty线程隔离开。

备注：对于长耗时的服务，实际上无论异步或者同步，都应该使用线程池，异步模式是基于nio+future实现，长耗时的网络io执行结果还是需要用到线程池去支持序列化，不应该消耗worker线程。

<2>dubbo的事件派发策略和线程池（默认使用了线程池）
dubbo基于netty。有5种派发策略：
默认是all：所有消息都派发到线程池，包括请求，响应，连接事件，断开事件，心跳等。 即worker线程接收到事件后，将该事件提交到业务线程池中，自己再去处理其他事。
direct：worker线程接收到事件后，由worker执行到底。
message：只有请求响应消息派发到线程池，其它连接断开事件，心跳等消息，直接在 IO线程上执行
execution：只请求消息派发到线程池，不含响应（客户端线程池），响应和其它连接断开事件，心跳等消息，直接在 IO 线程上执行
connection：在 IO 线程上，将连接断开事件放入队列，有序逐个执行，其它消息派发到线程池。

参考：https://blog.csdn.net/wanbf123/article/details/80768029，https://www.cnblogs.com/xhj123/p/9095278.html

<3>Dubbo提供的线程池策略
扩展接口 ThreadPool 的SPI实现有如下几种：
fixed：固定大小线程池，启动时建立线程，不关闭，一直持有（缺省）。
cached：缓存线程池，空闲一分钟自动删除，需要时重建。
limited：可伸缩线程池，但池中的线程数只会增长不会收缩。只增长不收缩的目的是为了避免收缩时突然带来大流量引起性能问题

4，tcp粘包问题分析与对策（https://www.cnblogs.com/kex1n/p/6502002.html，https://www.cnblogs.com/sidesky/p/6913109.html）
TCP粘包是指发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾，出现粘包现象的原因是多方面的，它既可能由发送方造成，也可能由接收方造成。

实际上是传输层不知道报文在哪里隔断，也就是说传输层不关注边界，应用层自己解决，因此任何基于tcp传输协议的通信框架都需要自己解决粘包问题。
备注：在流传输中出现，UDP不会出现粘包，因为它有消息边界（可以理解为每条消息）

TCP无保护消息边界的解决

针对这个问题，一般有3种解决方案（netty也是这样做）：
(1)发送固定长度的消息（不够的可以通过补0填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。
(2)把消息的尺寸与消息一块发送（消息头（消息头包含某条消息的长度）和消息体一块发送）
(3)使用特殊标记来区分消息间隔

5，为什么基于TCP的通讯程序需要进行封包和拆包

TCP是个"流"协议，所谓流，就是没有界限的一串数据，大家可以想想河里的流水，是连成一片的，其间是没有分界线的。但一般通讯程序开发是需要定义一个个相互独立的数据包的，比如用于登陆的数据包，用于注销的数据包。由于TCP"流"的特性以及网络状况，在进行数据传输时会出现以下几种情况。

假设我们连续调用两次send分别发送两段数据data1和data2,在接收端有以下几种接收情况(当然不止这几种情况,这里只列出了有代表性的情况).

A.先接收到data1,然后接收到data2.

B.先接收到data1的部分数据,然后接收到data1余下的部分以及data2的全部.

C.先接收到了data1的全部数据和data2的部分数据,然后接收到了data2的余下的数据.

D.一次性接收到了data1和data2的全部数据.

对于A这种情况正是我们需要的,不再做讨论.对于B,C,D的情况就是大家经常说的"粘包",就需要我们把接收到的数据进行拆包，拆成一个个独立的数据包，为了拆包就必须在发送端进行封包。

另：对于UDP来说就不存在拆包的问题,因为UDP是个"数据包"协议,也就是两段数据间是有界限的，在接收端要么接收不到数据要么就是接收一个完整的一段数据，不会少接收也不会多接收

6，netty针对tcp粘包的几种解决方案
<1>回车换行解码器：LineBasedFrameDecoder
<2>特殊分隔符解码器：DelimiterBasedFrameDecoder，回车换行解码器实际上是一种特殊的DelimiterBasedFrameDecoder解码器。
<3>定长解码器：FixedLengthFrameDecoder，对于定长消息，如果消息实际长度小于定长，则往往会进行补位操作，它在一定程度上导致了空间和资源的浪费。但是它的优点也是非常明显的，编解码比较简单，因此在实际项目中仍然有一定的应用场景
<4>基于包头不固定长度的解码器：LengthFieldBasedFrameDecoder，协议头中会携带长度字段，用于标识消息体或者整包消息的长度，例如SMPP、HTTP协议等。由于基于长度解码需求的通用性，以及为了降低用户的协议开发难度，Netty提供了LengthFieldBasedFrameDecoder，自动屏蔽TCP底层的拆包和粘包问题，只需要传入正确的参数，即可轻松解决“读半包“问题。LengthFieldBasedFrameDecoder比较灵活通用，由客户端告诉接收端，我传输的报文有多长了，接收端根据长度来解析。

7，netty面试题（https://blog.csdn.net/baiye_xing/article/details/76735113，https://zhuanlan.zhihu.com/p/55007263）

8，Netty 中Channel、EventLoop、Thread、EventLoopGroup之间的关系
EventLoop定义了Netty的核心抽象，用于处理连接的生命周期中所发生的事件。
一个EventLoopGroup包含一个或者多个EventLoop。
一个EventLoop在它的生命周期内只和一个Thread绑定。
所有由EventLoop处理的I/O事件都将在它专有的Thread上被处理。
一个Channel在它的生命周期内只注册于一个EventLoop。
一个EventLoop可能会被分配给一个或多个Channel。
在这种设计中，一个给定Channel的I/O操作都是由相同的Thread执行的。

9，NIOEventLoopGroup是怎么与Reactor关联在一起的呢？
其实NIOEventLoopGroup就是一个线程池实现，通过设置不同的NIOEventLoopGroup方式就可以对应三种不同的Reactor线程模型。
<1>单线程模型
EventLoopGroup bossGroup = new NioEventLoopGroup(1);
实例化了一个NIOEventLoopGroup，构造参数是1表示是单线程的线程池
<2>多线程模型
EventLoopGroup bossGroup = new NioEventLoopGroup(1);
EventLoopGroup workerGroup = new NioEventLoopGroup(N);
bossGroup 中只有一个线程, 在workerGroup线程池中我没有指定线程数量，所以默认是CPU 核心数乘以2， 因此对应的到Reactor线程模型中，这样设置的 NioEventLoopGroup 其实就是Reactor多线程模型。

<3>主从Reactor线程模型
EventLoopGroup bossGroup = new NioEventLoopGroup(4);
EventLoopGroup workerGroup = new NioEventLoopGroup(N);
Boss可以负责鉴权等工作

参考：https://blog.csdn.net/u010853261/article/details/62043709

10，rpc的future模式
pigeon的源码分析，对比一下源码，实际上就是netty多线程模型的底层线程池（如果不开线程，就是selector线程轮询结果）执行完毕，将结果放在当前的前程的threadLocal里面，将来调用future.get获取
参考：https://blog.csdn.net/ningdunquan/article/details/79910367

11，如何利用压测工具挖掘服务的性能？（jvm调优，gc调优）
<1>比如可以通过ptest进行压测，观测压测期间是否出现频繁的fullgc，如果出现，间接反映出对象的使用不太合理，比如一个逻辑只需要获取一个简单的数据，但是调用的服务返回的是一个大对象，假设调用链很长，这样就会长期占用很大的堆内存空间，因此最好根据需求（查询请求设置要求返回的字段数据）返回，不需要返回多余的数据(按需索取)，提高服务的响应性能。使用堆外内存，也会导致机器剩余可分配的堆内的空间少了，但是空间小了，full gc的也会变短，因此gc不需要扫描那么多空间。

<2>本地缓存由堆内存迁移到堆外内存，避免本地缓存的数据长期占用大量的堆内存空间和导致频繁的full gc。
参考：https://www.cnblogs.com/andy-zhou/p/5327288.html#_caption_0


12，深度理解select、poll和epoll
select的缺点：
<1>单个进程能够监视的文件描述符的数量存在最大限制，通常是1024，当然可以更改数量（如果修改，就得要自己重新编译内核，重新安装系统，实际很多创业公司都没自己的内核工程师），但由于select采用轮询的方式扫描文件描述符，文件描述符数量越多，性能越差；(在linux内核头文件中，有这样的定义：#define __FD_SETSIZE    1024
<2>内核/用户空间内存拷贝问题，select需要复制大量的句柄数据结构，产生巨大的开销；
<3>select返回的是含有整个句柄的数组，应用程序需要遍历整个数组才能发现哪些句柄发生了事件，实际上这个时间是o（n），时间开销比较高（select中，当有事件就绪时，内核修改参数以通知用户，用户需要遍历所有的fd判断是哪个fd就绪，应用程序索引就绪文件描述符的时间复杂度是O(n)，IO效率随着监听的fd的数目增加而线性下降。）
<4>select的触发方式是水平触发，应用程序如果没有完成对一个已经就绪的文件描述符进行IO操作，那么之后每次select调用还是会将这些文件描述符通知进程。

poll的缺点：
相比select模型，poll使用链表保存文件描述符，因此没有了监视文件数量的限制，但其他三个缺点依然存在（不断轮询所有的句柄数组，耗时还是很长）

参考：https://blog.csdn.net/wendy_keeping/article/details/76682861，https://blog.csdn.net/davidsguo008/article/details/73556811，https://blog.csdn.net/will130/article/details/51072819

epoll的特点：
epoll中注册了回调函数，当有就绪事件发生的时候，设备驱动程序调用回调函数，将就绪的fd添加到就绪链表rdllist中，调用epoll_wait时，将rdllist上就绪的fd发送给用户，应用程序索引就绪文件描述符的时间复杂度是O(1)，IO效率与fd的数目无关，

1）没有最大并发连接的限制，能打开FD的上限远大于1024（1G的内存上能监听约10万个端口）；

2）效率提升。不是轮询的方式，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数；

即epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，epoll的效率就会远远高于select和poll。

3）内存映射。epoll通过内核和用户空间共享一块内存来实现消息传递的。利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap 减少复制开销。epoll保证了每个fd在整个过程中只会拷贝一次（select，poll每次调用都要把fd集合从用户态往内核态拷贝一次）。


补充：
epoll永远比select高效吗？
不一定！
epoll适用于连接较多，活动数量较少的情况。
(1)epoll为了实现返回就绪的文件描述符，维护了一个红黑树和好多个等待队列，内核开销很大。如果此时监听了很少的文件描述符，底层的开销会得不偿失；

(2)epoll中注册了回调函数，当有时间发生时，服务器设备驱动调用回调函数将就绪的fd挂在rdllist上，如果有很多的活动，同一时间需要调用的回调函数数量太多，服务器压力太大。

select适用于连接较少的情况。
当select上监听的fd数量较少，内核通知用户现在有就绪事件发生，应用程序判断当前是哪个fd就绪所消耗的时间复杂度就会大大减小。

todo：
LT:level trigger, 水平触发模式
ET:edge trigger, 边缘触发模式

14,根据OSI参考模型分为(从上到下):物理层->数据链路层->网络层->传输层->会话层->表示层->应用层。
TCP/IP层次模型共分为四层：应用层->传输层->网络层->数据链路层。
参考：https://www.cnblogs.com/kevingrace/p/5909719.html


15,spring bean生命周期
Spring框架中，一旦把一个Bean纳入Spring IOC容器之中，这个Bean的生命周期就会交由容器进行管理，一般担当管理角色的是BeanFactory或者ApplicationContext,认识一下Bean的生命周期活动，对更好的利用它有很大的帮助：

下面以BeanFactory为例，说明一个Bean的生命周期活动
Bean的建立， 由BeanFactory读取Bean定义文件，并生成各个实例
Setter注入，执行Bean的属性依赖注入
BeanNameAware的setBeanName(), 如果实现该接口，则执行其setBeanName方法
BeanFactoryAware的setBeanFactory()，如果实现该接口，则执行其setBeanFactory方法
BeanPostProcessor的processBeforeInitialization()，如果有关联的processor，则在Bean初始化之前都会执行这个实例的processBeforeInitialization()方法
InitializingBean的afterPropertiesSet()，如果实现了该接口，则执行其afterPropertiesSet()方法
Bean定义文件中定义init-method
BeanPostProcessors的processAfterInitialization()，如果有关联的processor，则在Bean初始化之前都会执行这个实例的processAfterInitialization()方法
DisposableBean的destroy()，在容器关闭时，如果Bean类实现了该接口，则执行它的destroy()方法
Bean定义文件中定义destroy-method，在容器关闭时，可以在Bean定义文件中使用“destory-method”定义的方法

备注：BeanPostProcessor接口的作用：如果我们需要在Spring容器完成Bean的实例化、配置和其他的初始化前后添加一些自己的逻辑处理，我们就可以定义一个或者多个BeanPostProcessor接口的实现，然后注册到容器中去。

public class TestBeanPostProcessor implements BeanPostProcessor {

    /**
     * 实例化之后进行处理
     */
    public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException {
        return bean;
    }

    /**
     * 实例化之前进行处理
     */
    public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException {
        return bean;
    }
}
前者在初始化代码调用之后调用。
后者在实例化及依赖注入完成后，在任何初始化代码（比如配置文件中的init-method）调用之前调用。（参考：https://www.cnblogs.com/libra0920/p/6118157.html）

16，类装载器ClassLoader
工作机制：
类装载器就是寻找类的字节码文件并构造出类在JVM内部表示的对象组件。在Java中，类装载器装入JVM中，要经过以下步骤：
1.装载：查找和导入Class文件
2.链接：执行校验、准备和解析步骤，其中解析步骤是可以选择的：
校验：检查载入Class文件数据的正确性（校验是否是合法的字节码文件）
准备：给类的静态变量分配存储空间
解析：将符号引用转成直接引用
3.初始化：对类的静态变量、静态代码块执行初始化工作
4，在Java堆中生成一个代表这个类的java.lang.Class对象
类加载器工作由ClassLoader及其子类负责，ClassLoader是一个重要的Java运行时系统组件，它负责在运行时查找和装入Class字节码文件。JVM在运行时会产生三个ClassLoadre：根装载器、ExtClassLoader和AppClassLoader。根装载器不是ClassLoader的子类，负责装载JRE的核心类库。ExtClassLoader和AppClassLoader都是ClassLoader的子类。其中，EctClassLoader负责装载JRE扩展目录ext中的JAR类包，AppClassLoader负责装载Classpath路径下的类包。

JVM装载类时使用“双亲委托机制”，“双亲委托”是指当一个ClassLoader装载一个类时，除非显式地使用另一个ClassLoader，该类所依赖及引用的类也由这个ClassLoader载入：“委托机制”是指先委托父装载器寻找目标类，只有在找不到的情况下才从自己的类路径中查找并装载目标类。
ClassLoader的重要方法：
Class loadClass(String name)：name参数指定类装载器需要装载类的名字，必须使用全限定类名。该方法有一个重载方法loadClass(String name，boolean resolve)，resolve参数告诉类装载器是否需要解析该类。在初始化类之前，应考虑进行类解析的工作，但并不是所有的类都需要解析，若JVM值需知道该类是否存在或找出该类的超类，那么就不需要进行解析。
Class defineClass(String name,byte[] b,int off,int len)：将类文件的字节数组转换成JVM内部的java.lang.Class对象。字节数组可以从本地文件系统、远程网络获取。name为字节数组对应的全限定类名。
Class findSystemClass(String name)：从本地文件系统载入Class文件，若本地文件系统更不存在该Class文件，将抛出ClassNotFoundException异常。
Class findLoadedClass()：调用该方法来查看ClassLoader是否已装入某个类。若已装入，则返回java.lang.Class对象，否则返回null。
ClassLoader getParent()：获取类装载器的父装载器。

参考：https://www.cnblogs.com/fengbs/p/7082262.html






